{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dataset existence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230 files exist.\n"
     ]
    }
   ],
   "source": [
    "# check data existence\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "data_folder = Path.cwd().parent.joinpath(\"data/processed\")\n",
    "\n",
    "def check_data_existence(folder):\n",
    "    file_count = len(list(folder.glob(\"e*_ann.json\")))\n",
    "    if  file_count == 0:\n",
    "        raise Exception(\"Processed Data does not exist.\")\n",
    "    else:\n",
    "        print(\"{} files exist.\".format(file_count))\n",
    "\n",
    "\n",
    "check_data_existence(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Slot2 data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['market#general', 'company#general', 'company#sales', 'company#profit', 'company#amount', 'company#price', 'company#cost', 'business#general', 'business#sales', 'business#profit', 'business#amount', 'business#price', 'business#cost', 'product#general', 'product#sales', 'product#profit', 'product#amount', 'product#price', 'product#cost']\n"
     ]
    }
   ],
   "source": [
    "label_kinds = []\n",
    "\n",
    "# make labels (exclude NULL and OOD)\n",
    "for e in [\"market\", \"company\", \"business\", \"product\"]:\n",
    "    for a in [\"general\", \"sales\", \"profit\", \"amount\", \"price\", \"cost\"]:\n",
    "        label_kinds.append(e + \"#\" + a)\n",
    "        if e in [\"market\"]:\n",
    "            break;\n",
    "\n",
    "print(label_kinds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        categories  \\\n",
      "0  [company#sales, company#profit]   \n",
      "1                 [product#amount]   \n",
      "2                 [product#amount]   \n",
      "3                 [product#amount]   \n",
      "4                  [product#price]   \n",
      "\n",
      "                                            sentence             words  \n",
      "0  以上の結果、当連結会計年度の当社グループの業績は、売上高631億19百万円（前期比3.5％増...  [当社グループ, 当社グループ]  \n",
      "1  なお、当連結会計年度の生産量は、ブナピーを含めブナシメジ42,602ｔ（同5.5％増）、エリ...           [ブナシメジ]  \n",
      "2  平成27年４月の火災により生産を休止していた苫小牧第一きのこセンターが、工場を再建し、平成2...           [ブナシメジ]  \n",
      "3  また、改修のため一時生産を休止しておりました広川きのこセンターにおきまして、平成28年９月上...             [きのこ]  \n",
      "4      春から夏にかけましては個人消費の低迷などにより、きのこの価格は厳しい状況で推移いたしました             [きのこ]  \n",
      "[[(14, 20), (14, 20)], [(23, 28)], [(131, 136)], [(75, 78)], [(24, 27)]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "\n",
    "dataset = []\n",
    "labels = []\n",
    "\n",
    "for f in data_folder.glob(\"e*_ann.json\"):\n",
    "    with f.open(encoding=\"utf-8\") as j:\n",
    "        d = json.load(j)\n",
    "        for s in d[\"sentences\"]:\n",
    "            os = []\n",
    "            cs = []\n",
    "            ws = []\n",
    "            for o in s[\"opinions\"]:\n",
    "                category = o[\"category\"]\n",
    "                word = o[\"target\"]\n",
    "                if category in label_kinds and category not in cs:\n",
    "                    cs.append(category)\n",
    "                    ws.append(word)\n",
    "                    os.append((o[\"from\"], o[\"to\"]))\n",
    "            \n",
    "            if len(cs) > 0:\n",
    "                dataset.append(\n",
    "                    {\"sentence\": s[\"sentence\"], \n",
    "                     \"categories\": cs,\n",
    "                     \"words\": ws}\n",
    "                )\n",
    "                labels.append(os)\n",
    "\n",
    "dataset = pd.DataFrame(dataset)\n",
    "print(dataset.head(5))\n",
    "print(labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class DetectEntities():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.category_dict = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.category_dict = {}\n",
    "        for index, row in X.iterrows():\n",
    "            for c, w in zip(row[\"categories\"], row[\"words\"]):\n",
    "                if c not in self.category_dict:\n",
    "                    self.category_dict[c] = []\n",
    "                self.category_dict[c].append(w)\n",
    "\n",
    "        for c in self.category_dict:\n",
    "            cnt = Counter(self.category_dict[c])\n",
    "            freq = sorted(cnt.most_common(), key=lambda x: x[1])\n",
    "            self.category_dict[c] = [f[0] for f in freq]\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def search(self, sentence, word):\n",
    "        from_index = sentence.find(word)\n",
    "        if from_index > -1:\n",
    "            to_index = from_index + len(word)\n",
    "            return (from_index, to_index)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def predict(self, X, copy=True):\n",
    "        predictions = []\n",
    "        for index, row in X.iterrows():\n",
    "            s = row[\"sentence\"]\n",
    "            preds = []\n",
    "            for c in row[\"categories\"]:\n",
    "                if c not in self.category_dict:\n",
    "                    continue\n",
    "                for w in self.category_dict[c]:\n",
    "                    p = self.search(s, w)\n",
    "                    if p is not None:\n",
    "                        preds.append(p)\n",
    "                        break\n",
    "            predictions.append(preds)\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "model = DetectEntities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 事業ごとの状況をみますと、電線については、巻線や建設向けが減少しましたが、注力分野である鉄道車両用電線が中国向けを中心に大きく伸長しました\n",
      "predicted: [(21, 23)]\n",
      "true: [(21, 23)]\n",
      "---------------------------------------\n",
      "sentence: これらの結果、国際貨物取扱業の営業収益は6,260,681千円（前期比1.1％増）、セグメント利益（営業利益）は431,616千円（前期比13.6％増）となりました\n",
      "predicted: [(7, 14), (7, 14)]\n",
      "true: [(7, 14), (7, 14)]\n",
      "---------------------------------------\n",
      "sentence: 当社グループが係わる法人向けICT(*1)関連市場は、クラウドコンピューティングの普及を始めとする企業情報システムの変化、企業活動におけるビッグデータやIoT(*)等のICT利活用の進展、情報漏洩等に対応するセキュリティ需要の高まり、4K(*)配信等に伴うネットワーク利用の増大等により、継続的に拡大していくものと認識しております\n",
      "predicted: [(21, 25)]\n",
      "true: [(10, 25)]\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.fit(dataset)\n",
    "sample_indices = np.random.randint(0, len(dataset), 3)\n",
    "samples = dataset.iloc[sample_indices, :]\n",
    "pred_samples = model.predict(samples)\n",
    "true_samples = np.array(labels)[sample_indices]\n",
    "\n",
    "cnt = 0\n",
    "for i, row in samples.iterrows():\n",
    "    print(\"sentence: {}\".format(row[\"sentence\"]))\n",
    "    print(\"predicted: {}\".format(pred_samples[cnt]))\n",
    "    print(\"true: {}\".format(true_samples[cnt]))\n",
    "    cnt += 1\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 is 0.15256170217061774 (+/-0.01623943392960128)\n",
      "Precision is 0.1235013134597035 (+/-0.012661984288266091)\n",
      "Recall is 0.19964089725109377 (+/-0.023017783159678427)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def f1_score(preds, trues):\n",
    "    # calculate by micro\n",
    "    matches = 0\n",
    "    for_recall = 0\n",
    "    for_precision = 0\n",
    "\n",
    "    def safe_div(x1, x2):\n",
    "        return 0 if x2 == 0 else x1 / x2\n",
    "\n",
    "    for p, t in zip(preds, trues):\n",
    "        for_precision += len(p)\n",
    "        for_recall += len(t)\n",
    "        for _p in p:\n",
    "            if _p in t:\n",
    "                matches += 1\n",
    "\n",
    "    recall = safe_div(matches, for_recall)\n",
    "    precision = safe_div(matches, for_precision)\n",
    "    f1 = safe_div(2 * (precision * recall), (precision + recall))\n",
    "    return f1, precision, recall\n",
    "\n",
    "\n",
    "X = dataset\n",
    "y = np.array(labels)\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "f1s = []\n",
    "prs = []\n",
    "rcs = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    model.fit(X.iloc[train_index, :], y[train_index])\n",
    "    y_pred = model.predict(X.iloc[test_index, :])\n",
    "    y_true = y[test_index]\n",
    "    f1, pr, rc = f1_score(y_true, y_pred)\n",
    "    f1s.append(f1)\n",
    "    prs.append(pr)\n",
    "    rcs.append(rc)\n",
    "\n",
    "print(\"F1 is {} (+/-{})\".format(np.mean(f1s), np.std(f1s)))\n",
    "print(\"Precision is {} (+/-{})\".format(np.mean(prs), np.std(prs)))\n",
    "print(\"Recall is {} (+/-{})\".format(np.mean(rcs), np.std(rcs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 is 0.5477298340779891 (+/-0.2798488854225377)\n",
      "Precision is 0.5380430378410177 (+/-0.29346963830197725)\n",
      "Recall is 0.5634228991048145 (+/-0.2578640040410514)\n"
     ]
    }
   ],
   "source": [
    "# Show upper accuracy\n",
    "\n",
    "for train_index, test_index in cv.split(X):\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X.iloc[test_index, :])\n",
    "    y_true = y[test_index]\n",
    "    f1, pr, rc = f1_score(y_true, y_pred)\n",
    "    f1s.append(f1)\n",
    "    prs.append(pr)\n",
    "    rcs.append(rc)\n",
    "\n",
    "print(\"F1 is {} (+/-{})\".format(np.mean(f1s), np.std(f1s)))\n",
    "print(\"Precision is {} (+/-{})\".format(np.mean(prs), np.std(prs)))\n",
    "print(\"Recall is {} (+/-{})\".format(np.mean(rcs), np.std(rcs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
